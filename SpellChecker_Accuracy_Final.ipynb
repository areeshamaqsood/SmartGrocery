{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdada233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from spellchecker import SpellChecker\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bb48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamal Qureshi\\anaconda3\\envs\\FYP\\lib\\site-packages\\transformers\\configuration_utils.py:340: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training model used\n",
    "# Loading the tarining model to the system\n",
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-arabic\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c37141",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = ['Aata_Train','Achaar_Train', 'Anday_Train', 'Baisan_Train' , 'Channay_Train', 'Chawal_Train',\n",
    "               'Cheeni_Train', 'Dabal_Roti_Train', 'Dahi_Train', 'Doodh_Train', 'Elaichi_Train',\n",
    "               'Ghee_Train', 'Haldi_Train', 'Imli_Train', 'Namak_Train', 'Patti_Train', 'Sabun_Train',\n",
    "               'Sirka_Train', 'Surf_Train', 'Tael_Train']\n",
    "\n",
    "product_path_Test = ['Aata_Test','Achaar_Test', 'Anday_Test', 'Baisan_Test' , 'Channay_Test', 'Chawal_Test',\n",
    "               'Cheeni_Test', 'Dabal_Roti_Test', 'Dahi_Test', 'Doodh_Test', 'Elaichi_Test',\n",
    "               'Ghee_Test', 'Haldi_Test', 'Imli_Test', 'Namak_Test', 'Patti_Test', 'Sabun_Test',\n",
    "               'Sirka_Test', 'Surf_Test', 'Tael_Test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e32fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of words for spell checker\n",
    "word_list = ['أتار', 'عندي', 'أندي', 'بسن', 'بيسن', 'جني', 'شاني', 'أتى', 'أعتا', 'شعول', 'جاول',\n",
    "            'جيني', 'دبروتي', 'دبل روتي', 'دهي', 'دود', 'إلعَيْتي', 'إلعيتي', 'إِلَ عَيْتِي', 'إلى أيتي',\n",
    "            'كي', 'غي', 'حل دي', 'حلدي', 'إملي', 'نمك', 'بتي', 'صاب', 'سعب', 'سركا', 'سرف', 'تيل']\n",
    "\n",
    "# Used to calculate accuracy of each product\n",
    "word_dict = {0: ['أتى', 'أعتا'],\n",
    "            1: ['أتار'],\n",
    "            2: ['عندي', 'أندي'],\n",
    "            3: ['بيسن', 'بسن'],\n",
    "            4: ['جني', 'شاني'],\n",
    "            5: ['شعول', 'جاول'],\n",
    "            6: ['جيني'],\n",
    "            7: ['دبل روتي', 'دبروتي'],\n",
    "            8: ['دهي'],\n",
    "            9: ['دود'],\n",
    "            10: ['إلعَيْتي', 'إلعيتي', 'إِلَ عَيْتِي', 'إلى أيتي'],\n",
    "            11: ['غي', 'كي'],\n",
    "            12: ['حل دي', 'حلدي'],\n",
    "            13: ['إملي'],\n",
    "            14: ['نمك'],\n",
    "            15: ['بتي'],\n",
    "            16: ['صاب', 'سعب'],\n",
    "            17: ['سركا'],\n",
    "            18: ['سرف'],\n",
    "            19: ['تيل']}\n",
    "\n",
    "# Stores accuracy of each product\n",
    "dict_accuracy = {}\n",
    "\n",
    "# SpellChecker \n",
    "# Edit Distance = 5\n",
    "spell = SpellChecker(distance=5)\n",
    "spell.word_frequency.load_words(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ac06b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#Loop through each product\n",
    "for num, product in enumerate(product_path_Test):\n",
    "    \n",
    "    # Load audio files of each product     \n",
    "    path_audio = \"../Dataset/Grocery_Dataset_Complete_Folders/\"+product\n",
    "    data = librosa.util.find_files(path_audio, ext=['wav'])\n",
    "    \n",
    "    # Pass each audio file to the model. Store the result in a list\n",
    "    pred_word = []\n",
    "    for vn in data:\n",
    "\n",
    "        # Load file         \n",
    "        voice_data = librosa.load(vn, sr=16000, mono=True)\n",
    "\n",
    "        inputs = processor(voice_data[0], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        predicted_word = processor.batch_decode(predicted_ids)\n",
    "\n",
    "        # Append the word to the list\n",
    "        pred_word.append(predicted_word)\n",
    "        \n",
    "    # Corrects the predicted word according to the dictionary     \n",
    "    corrected_word = []\n",
    "    \n",
    "    for pred in pred_word:\n",
    "        corrected_word.append(spell.correction(pred[0]))\n",
    "    \n",
    "    correctly_pred = 0\n",
    "\n",
    "    # For each corrected word find the accuracy to\n",
    "    # how to close all the audio files were correctly\n",
    "    # mapped     \n",
    "    for word in corrected_word:\n",
    "        actual_word = word_dict[num]\n",
    "\n",
    "        if word in actual_word:\n",
    "            correctly_pred += 1\n",
    "\n",
    "    # Finding Percentage of Correctly Predicted\n",
    "    accuracy = (float(correctly_pred)/float(len(corrected_word))) * 100\n",
    "    \n",
    "    # Store the accuracy percentage w.r.t to the \n",
    "    # product in a dictionary\n",
    "    dict_accuracy[product_path_Test[num]] = accuracy\n",
    "    \n",
    "    # Reset all the lists\n",
    "    pred_word.clear()\n",
    "    corrected_word.clear()\n",
    "    \n",
    "    print(num)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3acc91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aata_Test  :  60.0\n",
      "Achaar_Test  :  77.77777777777779\n",
      "Anday_Test  :  100.0\n",
      "Baisan_Test  :  100.0\n",
      "Channay_Test  :  90.0\n",
      "Chawal_Test  :  88.88888888888889\n",
      "Cheeni_Test  :  100.0\n",
      "Dabal_Roti_Test  :  50.0\n",
      "Dahi_Test  :  90.0\n",
      "Doodh_Test  :  90.0\n",
      "Elaichi_Test  :  70.0\n",
      "Ghee_Test  :  90.0\n",
      "Haldi_Test  :  90.0\n",
      "Imli_Test  :  100.0\n",
      "Namak_Test  :  90.0\n",
      "Patti_Test  :  77.77777777777779\n",
      "Sabun_Test  :  90.0\n",
      "Sirka_Test  :  70.0\n",
      "Surf_Test  :  90.0\n",
      "Tael_Test  :  90.0\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_accuracy.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe33b00",
   "metadata": {},
   "source": [
    "Following result was accomp on completely unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f6c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
